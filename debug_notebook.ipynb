{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e6f4ba-308a-4b98-ba26-ee3ed102ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:loading configuration file model_files/bert-large-uncased/config.json\n",
      "INFO:Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"num_rnn_layer\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"rnn\": \"lstm\",\n",
      "  \"rnn_dropout\": 0.0,\n",
      "  \"rnn_hidden\": 768,\n",
      "  \"split\": 10,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"transformers_version\": \"4.6.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n",
      "torch.Size([64, 34])\n",
      "torch.Size([64, 35])\n",
      "torch.Size([64, 36])\n",
      "torch.Size([64, 35])\n",
      "torch.Size([64, 35])\n",
      "torch.Size([64, 36])\n",
      "torch.Size([64, 35])\n",
      "torch.Size([64, 34])\n",
      "torch.Size([20, 35])\n"
     ]
    }
   ],
   "source": [
    "from optimization import *\n",
    "from configuration_bert import *\n",
    "from tokenization_bert import *\n",
    "from modeling_bert import *\n",
    "\n",
    "import pathlib\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "from typing import Dict, List, Tuple\n",
    "from copy import deepcopy\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler, IterableDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "from time import sleep\n",
    "\n",
    "from preparation_01 import *  #< this source contains all the necessary functions for the model to run.\n",
    "\n",
    "check_mps_device()\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")  # Use Metal Performance Shaders (MPS) backend\n",
    "    print(\"Using MPS (Metal) device on my new MAC M2 hihi\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "    \n",
    "##### test input data. \n",
    "input_data_path = \"./example/input_data/input.txt\"\n",
    "\n",
    "##### define the BERT model and tokenizer.\n",
    "config, model_class, tokenizer = define_BERT_model()\n",
    "\n",
    "##### read the input data into batches of tokenized data.\n",
    "batch_size = 64\n",
    "dataset = LineByLineBatchedTextDataset(file_path=input_data_path, tokenizer=tokenizer, batch_size=batch_size)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "for batch in data_loader:\n",
    "    input_ids, attention_masks = batch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
